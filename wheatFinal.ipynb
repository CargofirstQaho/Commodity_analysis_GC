{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CargofirstQaho/Commodity_analysis_GC/blob/main/wheatFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },

    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m-PPRpvisLlg",
        "outputId": "820ff064-86ee-446f-b264-2af971cabf5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Collecting opencv-python-headless==4.8.0.76\n",
            "  Using cached opencv_python_headless-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.24.4 (from versions: 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.24.4\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: streamlit==1.38.0 in /usr/local/lib/python3.12/dist-packages (1.38.0)\n",
            "Requirement already satisfied: pyngrok==7.2.0 in /usr/local/lib/python3.12/dist-packages (7.2.0)\n",
            "Requirement already satisfied: watchdog==4.0.0 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (18.1.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (4.15.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok==7.2.0) (6.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (2.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair<6,>=4.0->streamlit==1.38.0) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit==1.38.0) (1.17.0)\n",
            "app.py written\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c3cdf7f1-e3e5-472b-b069-fa935c2f6a9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c3cdf7f1-e3e5-472b-b069-fa935c2f6a9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Gemini_Generated_Image_wov1y8wov1y8wov1.png to Gemini_Generated_Image_wov1y8wov1y8wov1.png\n",
            "Public URL: https://camphoric-nonevanescently-maynard.ngrok-free.dev\n",
            "If the URL fails, restart this cell. Remove ngrok token cell before sharing notebook.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-26T12:05:35+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-26 12:06:21.392 MediaFileHandler: Missing file 5788d59cad97efcad4797c90483f7fd02166f61ab593bb8eb3d1d3c2.jpg\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --only-binary=:all: opencv-python-headless==4.8.0.76 numpy==1.24.4 pillow==9.5.0 scikit-image==0.21.0\n",
        "!pip install --only-binary=:all: streamlit==1.38.0 pyngrok==7.2.0 watchdog==4.0.0 requests\n",
        "\n",
        "import os\n",
        "# set your token here then delete/clear this cell after use\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = \"35gSLvFYhBHyiL1IDMvwLuuGCxK_3wDSUYrMugCvGS8MgPSFk\"\n",
        "\n",
        "app_code = r\"\"\"\n",
        "# app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "st.set_page_config(page_title='Wheat Quality Analyzer', layout='wide')\n",
        "st.title('Wheat Quality Analyzer')\n",
        "\n",
        "st.markdown('Counts: total, good, broken, foreign matter, spoiled, discoloured. Color classes: light brown, brown, dark brown, black. Averages reported in mm. Percentages show class share of total detected grains.')\n",
        "\n",
        "# Sidebar tuning (wheat-specific)\n",
        "st.sidebar.header('Tunable thresholds')\n",
        "broken_ratio = st.sidebar.slider('Broken length ratio (of median)', 0.4, 0.95, 0.70, 0.01)\n",
        "min_area = st.sidebar.slider('Min contour area (px) filter', 20, 400, 80, 1)\n",
        "\n",
        "# Foreign matter heuristics\n",
        "foreign_solidity_thresh = st.sidebar.slider('Foreign solidity threshold', 0.10, 0.95, 0.60, 0.01)\n",
        "foreign_area_multiplier = st.sidebar.slider('Foreign area multiplier (vs median area)', 1.0, 10.0, 5.0, 0.1)\n",
        "foreign_aspect_ratio = st.sidebar.slider('Foreign extreme aspect ratio', 1.5, 6.0, 3.5, 0.1)\n",
        "foreign_circularity_thresh = st.sidebar.slider('Foreign circularity threshold (lower = more foreign)', 0.10, 1.00, 0.35, 0.01)\n",
        "\n",
        "# Discolour/spoiled heuristics (LAB space)\n",
        "discolour_percentile = st.sidebar.slider('Discolour b-channel percentile (lower b = greyer)', 1, 50, 25, 1)\n",
        "spoiled_L_percentile = st.sidebar.slider('Spoiled darkness L percentile (lower L = darker)', 1, 40, 15, 1)\n",
        "\n",
        "# Color labeling\n",
        "k_colors = st.sidebar.slider('Color clusters (k-means on LAB)', 2, 5, 4, 1)\n",
        "light_dark_split = st.sidebar.slider('Light/Dark L threshold (0-255)', 60, 190, 120, 1)\n",
        "\n",
        "# mm calibration (replace if you have known mm-per-pixel)\n",
        "target_avg_mm = st.sidebar.slider('Target avg kernel length for calibration (mm)', 5.5, 8.5, 7.0, 0.1)\n",
        "\n",
        "# Image processing utils\n",
        "def clahe_rgb(img_bgr):\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L, A, B = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    Lc = clahe.apply(L)\n",
        "    labc = cv2.merge([Lc, A, B])\n",
        "    return cv2.cvtColor(labc, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "def preprocess(img):\n",
        "    # Contrast-normalize, then grayscale threshold for wheat kernels\n",
        "    img_c = clahe_rgb(img)\n",
        "    gray = cv2.cvtColor(img_c, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 51, 5)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    cleaned = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    dilated = cv2.dilate(cleaned, kernel, iterations=1)\n",
        "    return img_c, gray, dilated\n",
        "\n",
        "def extract_grain_contours(binary_mask, min_area_px):\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    filtered = [c for c in contours if cv2.contourArea(c) > float(min_area_px)]\n",
        "    return filtered\n",
        "\n",
        "def circularity(contour):\n",
        "    area = cv2.contourArea(contour)\n",
        "    perim = cv2.arcLength(contour, True) + 1e-6\n",
        "    return float(4.0 * np.pi * area / (perim * perim))\n",
        "\n",
        "def grain_features(img_bgr, gray, contour):\n",
        "    area = cv2.contourArea(contour)\n",
        "    rect = cv2.minAreaRect(contour)\n",
        "    (cx, cy), (w, h), angle = rect\n",
        "    length = max(w, h)\n",
        "    width = min(w, h)\n",
        "    aspect_ratio = (length + 1.0) / (width + 1.0)\n",
        "\n",
        "    # masks\n",
        "    mask = np.zeros_like(gray)\n",
        "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
        "\n",
        "    mean_intensity = float(cv2.mean(gray, mask=mask)[0])\n",
        "\n",
        "    hull = cv2.convexHull(contour)\n",
        "    hull_area = cv2.contourArea(hull) + 1e-6\n",
        "    solidity = float(area / hull_area)\n",
        "    circ = circularity(contour)\n",
        "\n",
        "    # LAB features\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    L = lab[:,:,0]; A = lab[:,:,1]; B = lab[:,:,2]\n",
        "    mean_L = float(cv2.mean(L, mask=mask)[0])\n",
        "    mean_A = float(cv2.mean(A, mask=mask)[0])\n",
        "    mean_B = float(cv2.mean(B, mask=mask)[0])\n",
        "\n",
        "    polygon = contour.reshape(-1, 2).tolist()\n",
        "\n",
        "    return {\n",
        "        \"contour\": contour,\n",
        "        \"polygon\": polygon,\n",
        "        \"area\": float(area),\n",
        "        \"length_px\": float(length),\n",
        "        \"width_px\": float(width),\n",
        "        \"aspect_ratio\": float(aspect_ratio),\n",
        "        \"mean_intensity\": mean_intensity,\n",
        "        \"solidity\": solidity,\n",
        "        \"circularity\": circ,\n",
        "        \"cx\": float(cx),\n",
        "        \"cy\": float(cy),\n",
        "        \"L\": mean_L,\n",
        "        \"A\": mean_A,\n",
        "        \"B\": mean_B\n",
        "    }\n",
        "\n",
        "def classify_wheat(features_list,\n",
        "                   broken_ratio,\n",
        "                   discolour_percentile,\n",
        "                   spoiled_L_percentile,\n",
        "                   foreign_solidity_thresh,\n",
        "                   foreign_area_multiplier,\n",
        "                   foreign_ar_thresh,\n",
        "                   foreign_circ_thresh):\n",
        "    results = []\n",
        "    # robust medians for scale references\n",
        "    lengths = np.array([f[\"length_px\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    areas = np.array([f[\"area\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    Ls = np.array([f[\"L\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    Bs = np.array([f[\"B\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "\n",
        "    median_len = float(np.median(lengths)) if len(lengths) else 0.0\n",
        "    broken_threshold = broken_ratio * median_len\n",
        "\n",
        "    # lower B (bluer/greyer) → more discolour; lower L → darker\n",
        "    discolour_threshold = float(np.percentile(Bs, discolour_percentile)) if len(Bs) else 0.0\n",
        "    spoiled_threshold = float(np.percentile(Ls, spoiled_L_percentile)) if len(Ls) else 0.0\n",
        "\n",
        "    median_area = float(np.median(areas)) if len(areas) else 0.0\n",
        "\n",
        "    for f in features_list:\n",
        "        is_broken = f[\"length_px\"] < broken_threshold\n",
        "\n",
        "        is_foreign = (f[\"solidity\"] < foreign_solidity_thresh) or \\\n",
        "                     (f[\"area\"] > foreign_area_multiplier * median_area) or \\\n",
        "                     (f[\"aspect_ratio\"] > foreign_ar_thresh) or \\\n",
        "                     (f[\"circularity\"] < foreign_circ_thresh)\n",
        "\n",
        "        is_spoiled = (f[\"L\"] <= spoiled_threshold) and (f[\"solidity\"] < 0.8)\n",
        "        is_discoloured = (f[\"B\"] <= discolour_threshold) and (not is_spoiled)\n",
        "\n",
        "        is_good = (not is_broken) and (not is_foreign) and (not is_spoiled) and (not is_discoloured)\n",
        "\n",
        "        label = \"good\"\n",
        "        if is_foreign:\n",
        "            label = \"foreign\"\n",
        "        elif is_broken:\n",
        "            label = \"broken\"\n",
        "        elif is_spoiled:\n",
        "            label = \"spoiled\"\n",
        "        elif is_discoloured:\n",
        "            label = \"discoloured\"\n",
        "\n",
        "        results.append({**f,\n",
        "                        \"is_broken\": bool(is_broken),\n",
        "                        \"is_foreign\": bool(is_foreign),\n",
        "                        \"is_spoiled\": bool(is_spoiled),\n",
        "                        \"is_discoloured\": bool(is_discoloured),\n",
        "                        \"is_good\": bool(is_good),\n",
        "                        \"label\": label})\n",
        "\n",
        "    meta = {\n",
        "        \"median_len_px\": median_len,\n",
        "        \"broken_threshold_px\": broken_threshold,\n",
        "        \"discolour_threshold_B\": discolour_threshold,\n",
        "        \"spoiled_threshold_L\": spoiled_threshold,\n",
        "        \"median_area_px\": median_area\n",
        "    }\n",
        "    return results, meta\n",
        "\n",
        "def color_label_from_lab(L, A, B, light_dark_split):\n",
        "    # Simple interpretable bins\n",
        "    # Light vs dark by L; chroma by A/B roughly maps to brownness\n",
        "    if L <= 40:\n",
        "        return \"black\"\n",
        "    if L <= light_dark_split:\n",
        "        # darker range\n",
        "        if B >= 140 and A >= 140:\n",
        "            return \"dark brown\"\n",
        "        else:\n",
        "            return \"brown\"\n",
        "    else:\n",
        "        # lighter range\n",
        "        if B >= 140 and A >= 140:\n",
        "            return \"brown\"\n",
        "        else:\n",
        "            return \"light brown\"\n",
        "\n",
        "def annotate_polygons(img, results):\n",
        "    annotated = img.copy()\n",
        "    colors = {\n",
        "        \"good\": (0, 200, 0),\n",
        "        \"broken\": (0, 0, 255),\n",
        "        \"discoloured\": (0, 165, 255),\n",
        "        \"spoiled\": (128, 0, 128),\n",
        "        \"foreign\": (255, 0, 0)\n",
        "    }\n",
        "    for r in results:\n",
        "        contour = r[\"contour\"]\n",
        "        label = r.get(\"label\", \"good\")\n",
        "        color = colors.get(label, (255,255,255))\n",
        "        cv2.drawContours(annotated, [contour], -1, color, 2, cv2.LINE_AA)\n",
        "        cx, cy = int(r[\"cx\"]), int(r[\"cy\"])\n",
        "        cv2.circle(annotated, (cx, cy), 2, color, -1)\n",
        "    return annotated\n",
        "\n",
        "def pixels_to_mm(avg_pixel_length_px, target_avg_mm=7.0):\n",
        "    if avg_pixel_length_px <= 0:\n",
        "        return 0.0\n",
        "    return float(target_avg_mm / avg_pixel_length_px)\n",
        "\n",
        "# Streamlit inputs\n",
        "uploaded = st.file_uploader(\"Upload a wheat image (jpg/png)\", type=[\"jpg\",\"jpeg\",\"png\"])\n",
        "camera_img = st.camera_input(\"Or capture from your camera\")\n",
        "\n",
        "image_bytes = None\n",
        "if uploaded is not None:\n",
        "    image_bytes = uploaded.read()\n",
        "elif camera_img is not None:\n",
        "    image_bytes = camera_img.getvalue()\n",
        "\n",
        "if image_bytes is not None:\n",
        "    pil = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    img = np.array(pil)[:, :, ::-1].copy()\n",
        "    img_c, gray, binary = preprocess(img)\n",
        "    contours = extract_grain_contours(binary, min_area)\n",
        "    feats = [grain_features(img_c, gray, c) for c in contours]\n",
        "    results, meta = classify_wheat(\n",
        "        feats,\n",
        "        broken_ratio,\n",
        "        discolour_percentile,\n",
        "        spoiled_L_percentile,\n",
        "        foreign_solidity_thresh,\n",
        "        foreign_area_multiplier,\n",
        "        foreign_aspect_ratio,\n",
        "        foreign_circularity_thresh\n",
        "    )\n",
        "\n",
        "    # Color labels\n",
        "    for r in results:\n",
        "        r[\"color_label\"] = color_label_from_lab(r[\"L\"], r[\"A\"], r[\"B\"], light_dark_split)\n",
        "\n",
        "    total = len(results)\n",
        "    count_good = sum(1 for r in results if r[\"label\"] == \"good\")\n",
        "    count_broken = sum(1 for r in results if r[\"label\"] == \"broken\")\n",
        "    count_discoloured = sum(1 for r in results if r[\"label\"] == \"discoloured\")\n",
        "    count_spoiled = sum(1 for r in results if r[\"label\"] == \"spoiled\")\n",
        "    count_foreign = sum(1 for r in results if r[\"label\"] == \"foreign\")\n",
        "\n",
        "    # Color counts\n",
        "    color_classes = [\"light brown\", \"brown\", \"dark brown\", \"black\"]\n",
        "    color_counts = {c: sum(1 for r in results if r.get(\"color_label\")==c) for c in color_classes}\n",
        "\n",
        "    avg_len_px = float(np.mean([r[\"length_px\"] for r in results])) if total else 0.0\n",
        "    avg_wid_px = float(np.mean([r[\"width_px\"] for r in results])) if total else 0.0\n",
        "    mm_per_px = pixels_to_mm(avg_len_px, target_avg_mm=target_avg_mm) if avg_len_px > 0 else 0.0\n",
        "    avg_len_mm = avg_len_px * mm_per_px\n",
        "    avg_wid_mm = avg_wid_px * mm_per_px\n",
        "\n",
        "    pct_good = (count_good / total * 100.0) if total else 0.0\n",
        "    pct_broken = (count_broken / total * 100.0) if total else 0.0\n",
        "    pct_discoloured = (count_discoloured / total * 100.0) if total else 0.0\n",
        "    pct_spoiled = (count_spoiled / total * 100.0) if total else 0.0\n",
        "    pct_foreign = (count_foreign / total * 100.0) if total else 0.0\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.subheader(\"Counts\")\n",
        "        st.metric(\"Total detected\", total)\n",
        "        st.metric(\"Good (normal)\", f\"{count_good} ({pct_good:.1f}%)\")\n",
        "        st.metric(\"Broken\", f\"{count_broken} ({pct_broken:.1f}%)\")\n",
        "        st.metric(\"Discoloured\", f\"{count_discoloured} ({pct_discoloured:.1f}%)\")\n",
        "        st.metric(\"Spoiled\", f\"{count_spoiled} ({pct_spoiled:.1f}%)\")\n",
        "        st.metric(\"Foreign matter\", f\"{count_foreign} ({pct_foreign:.1f}%)\")\n",
        "\n",
        "        st.subheader(\"Averages (mm)\")\n",
        "        st.write(f\"Average length: **{avg_len_mm:.2f} mm**\")\n",
        "        st.write(f\"Average width: **{avg_wid_mm:.2f} mm**\")\n",
        "        st.caption(\"Calibration: detected avg kernel length mapped to the sidebar value (default 7.0 mm). Replace with known mm-per-pixel for accurate absolute sizing.\")\n",
        "\n",
        "        st.subheader(\"Color distribution\")\n",
        "        for k in color_classes:\n",
        "            pct = (color_counts[k] / total * 100.0) if total else 0.0\n",
        "            st.write(f\"- **{k}:** {color_counts[k]} ({pct:.1f}%)\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Annotated (polygons)\")\n",
        "        annotated = annotate_polygons(img_c, results)\n",
        "        display_img = annotated[:, :, ::-1]\n",
        "        st.image(display_img, caption=\"Green=Good, Red=Broken, Orange=Discoloured, Purple=Spoiled, Blue=Foreign\", use_column_width=True)\n",
        "\n",
        "        buffer = BytesIO()\n",
        "        pil_out = Image.fromarray(display_img)\n",
        "        pil_out.save(buffer, format=\"PNG\")\n",
        "        buffer.seek(0)\n",
        "        st.download_button(\"Download annotated image\", data=buffer, file_name=\"annotated_wheat.png\", mime=\"image/png\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload an image or use the camera to start analysis.\")\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"app.py written\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import subprocess, time, os, requests\n",
        "from pyngrok import ngrok\n",
        "\n",
        "token = os.environ.get(\"NGROK_AUTHTOKEN\", \"\")\n",
        "if token:\n",
        "    ngrok.set_auth_token(token)\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "timeout = 40\n",
        "while True:\n",
        "    try:\n",
        "        r = requests.get(\"http://localhost:8501\")\n",
        "        if r.status_code < 500:\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "    if time.time() - start > timeout:\n",
        "        print(\"Warning: Streamlit did not respond within timeout; check logs.\")\n",
        "        break\n",
        "    time.sleep(0.5)\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\").public_url\n",
        "print(\"Public URL:\", public_url)\n",
        "print(\"If the URL fails, restart this cell. Remove ngrok token cell before sharing notebook.\")\n",
        "\n",
        "import time, sys\n",
        "for _ in range(200):\n",
        "    line = proc.stderr.readline()\n",
        "    if not line:\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "    try:\n",
        "        print(line.decode('utf-8', errors='ignore').rstrip())\n",
        "    except:\n",
        "        print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOtU74TksMdK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHwDJszLDMMHPrwYl0YJQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
