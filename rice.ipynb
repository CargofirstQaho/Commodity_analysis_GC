{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONiZDjuozbcCa9yj3jTntE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },

  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CargofirstQaho/Commodity_analysis_GC/blob/main/rice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jDP2sdnZB09o",
        "outputId": "f862b413-b432-4177-84e9-7f42daf75531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Collecting opencv-python-headless==4.8.0.76\n",
            "  Downloading opencv_python_headless-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.24.4 (from versions: 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.24.4\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting streamlit==1.38.0\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok==7.2.0\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting watchdog==4.0.0\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (1.9.0)\n",
            "Collecting cachetools<6,>=4.0 (from streamlit==1.38.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (2.0.2)\n",
            "Collecting packaging<25,>=20 (from streamlit==1.38.0)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (2.2.2)\n",
            "Collecting pillow<11,>=7.1.0 (from streamlit==1.38.0)\n",
            "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (18.1.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (13.9.4)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit==1.38.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (4.15.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.38.0)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok==7.2.0) (6.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (2.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair<6,>=4.0->streamlit==1.38.0) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit==1.38.0) (1.17.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: watchdog, tenacity, pyngrok, pillow, packaging, cachetools, pydeck, streamlit\n",
            "\u001b[2K  Attempting uninstall: watchdog\n",
            "\u001b[2K    Found existing installation: watchdog 6.0.0\n",
            "\u001b[2K    Uninstalling watchdog-6.0.0:\n",
            "\u001b[2K      Successfully uninstalled watchdog-6.0.0\n",
            "\u001b[2K  Attempting uninstall: tenacity\n",
            "\u001b[2K    Found existing installation: tenacity 9.1.2\n",
            "\u001b[2K    Uninstalling tenacity-9.1.2:\n",
            "\u001b[2K      Successfully uninstalled tenacity-9.1.2\n",
            "\u001b[2K  Attempting uninstall: pillow\n",
            "\u001b[2K    Found existing installation: pillow 11.3.0\n",
            "\u001b[2K    Uninstalling pillow-11.3.0:\n",
            "\u001b[2K      Successfully uninstalled pillow-11.3.0\n",
            "\u001b[2K  Attempting uninstall: packaging\n",
            "\u001b[2K    Found existing installation: packaging 25.0\n",
            "\u001b[2K    Uninstalling packaging-25.0:\n",
            "\u001b[2K      Successfully uninstalled packaging-25.0\n",
            "\u001b[2K  Attempting uninstall: cachetools\n",
            "\u001b[2K    Found existing installation: cachetools 6.2.2\n",
            "\u001b[2K    Uninstalling cachetools-6.2.2:\n",
            "\u001b[2K      Successfully uninstalled cachetools-6.2.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [streamlit]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.19.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "google-adk 1.19.0 requires watchdog<7.0.0,>=6.0.0, but you have watchdog 4.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-5.5.2 packaging-24.2 pillow-10.4.0 pydeck-0.9.1 pyngrok-7.2.0 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "packaging"
                ]
              },
              "id": "7225d3cb7ddc49a39c63522d052884b4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --only-binary=:all: opencv-python-headless==4.8.0.76 numpy==1.24.4 pillow==9.5.0 scikit-image==0.21.0\n",
        "!pip install --only-binary=:all: streamlit==1.38.0 pyngrok==7.2.0 watchdog==4.0.0 requests\n"
      ]
    },
    
    {
      "cell_type": "code",
      "source": [
        "app_code = r\"\"\"\n",
        "# app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "st.set_page_config(page_title='Rice Quality Analyzer', layout='wide')\n",
        "st.title('Rice Quality Analyzer ')\n",
        "\n",
        "st.markdown('Counts: total, broken, normal, foreign matter, damaged/discoloured, chalky. Averages reported in mm. Percentages show class share of total detected grains.')\n",
        "\n",
        "# Sidebar tuning\n",
        "st.sidebar.header('Tunable thresholds')\n",
        "broken_ratio = st.sidebar.slider('Broken length ratio (of median)', 0.4, 0.95, 0.75, 0.01)\n",
        "chalky_percentile = st.sidebar.slider('Chalky intensity percentile (higher = more chalky)', 50, 99, 75, 1)\n",
        "damaged_percentile = st.sidebar.slider('Damaged/discoloured intensity percentile (lower = more damaged)', 1, 50, 20, 1)\n",
        "min_area = st.sidebar.slider('Min contour area (px) filter', 10, 200, 50, 1)\n",
        "foreign_solidity_thresh = st.sidebar.slider('Foreign solidity threshold (lower means more likely foreign)', 0.1, 0.95, 0.55, 0.01)\n",
        "foreign_area_multiplier = st.sidebar.slider('Foreign area multiplier (relative to median area)', 1.5, 10.0, 5.0, 0.1)\n",
        "foreign_aspect_ratio = st.sidebar.slider('Foreign extreme aspect ratio', 1.5, 6.0, 3.0, 0.1)\n",
        "\n",
        "\n",
        "# Image processing utils\n",
        "def preprocess(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 51, 5)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    dilated = cv2.dilate(opened, kernel, iterations=1)\n",
        "    return gray, dilated\n",
        "\n",
        "def extract_grain_contours(binary_mask, min_area_px):\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    filtered = [c for c in contours if cv2.contourArea(c) > float(min_area_px)]\n",
        "    return filtered\n",
        "\n",
        "def grain_features(gray, contour):\n",
        "    area = cv2.contourArea(contour)\n",
        "    rect = cv2.minAreaRect(contour)\n",
        "    (cx, cy), (w, h), angle = rect\n",
        "    length = max(w, h)\n",
        "    width = min(w, h)\n",
        "    aspect_ratio = (length + 1.0) / (width + 1.0)\n",
        "    mask = np.zeros_like(gray)\n",
        "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
        "    mean_intensity = float(cv2.mean(gray, mask=mask)[0])\n",
        "    hull = cv2.convexHull(contour)\n",
        "    hull_area = cv2.contourArea(hull) + 1e-6\n",
        "    solidity = float(area / hull_area)\n",
        "    polygon = contour.reshape(-1, 2).tolist()\n",
        "    return {\n",
        "        \"contour\": contour,\n",
        "        \"polygon\": polygon,\n",
        "        \"area\": float(area),\n",
        "        \"length_px\": float(length),\n",
        "        \"width_px\": float(width),\n",
        "        \"aspect_ratio\": float(aspect_ratio),\n",
        "        \"mean_intensity\": mean_intensity,\n",
        "        \"solidity\": solidity,\n",
        "        \"cx\": float(cx),\n",
        "        \"cy\": float(cy)\n",
        "    }\n",
        "\n",
        "def classify_grains(features_list, broken_ratio, chalky_percentile, damaged_percentile,\n",
        "                    foreign_solidity_thresh, foreign_area_multiplier, foreign_ar_thresh):\n",
        "    results = []\n",
        "    lengths = np.array([f[\"length_px\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    median_len = float(np.median(lengths)) if len(lengths) else 0.0\n",
        "    broken_threshold = broken_ratio * median_len\n",
        "\n",
        "    intensities = np.array([f[\"mean_intensity\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    chalky_threshold = float(np.percentile(intensities, chalky_percentile)) if len(intensities) else 255.0\n",
        "    damaged_threshold = float(np.percentile(intensities, damaged_percentile)) if len(intensities) else 0.0\n",
        "\n",
        "    areas = np.array([f[\"area\"] for f in features_list]) if features_list else np.array([0.0])\n",
        "    median_area = float(np.median(areas)) if len(areas) else 0.0\n",
        "\n",
        "    for f in features_list:\n",
        "        is_broken = f[\"length_px\"] < broken_threshold\n",
        "        is_chalky = f[\"mean_intensity\"] >= chalky_threshold\n",
        "        is_damaged = f[\"mean_intensity\"] <= damaged_threshold\n",
        "        is_foreign = (f[\"solidity\"] < foreign_solidity_thresh) or \\\n",
        "                     (f[\"area\"] > foreign_area_multiplier * median_area) or \\\n",
        "                     (f[\"aspect_ratio\"] > foreign_ar_thresh)\n",
        "        is_normal = (not is_broken) and (not is_chalky) and (not is_damaged) and (not is_foreign)\n",
        "        label = \"normal\"\n",
        "        if is_foreign:\n",
        "            label = \"foreign\"\n",
        "        elif is_broken:\n",
        "            label = \"broken\"\n",
        "        elif is_damaged:\n",
        "            label = \"damaged\"\n",
        "        elif is_chalky:\n",
        "            label = \"chalky\"\n",
        "        results.append({**f,\n",
        "                        \"is_broken\": bool(is_broken),\n",
        "                        \"is_chalky\": bool(is_chalky),\n",
        "                        \"is_damaged\": bool(is_damaged),\n",
        "                        \"is_foreign\": bool(is_foreign),\n",
        "                        \"is_normal\": bool(is_normal),\n",
        "                        \"label\": label})\n",
        "    meta = {\n",
        "        \"median_len_px\": median_len,\n",
        "        \"broken_threshold_px\": broken_threshold,\n",
        "        \"chalky_threshold\": chalky_threshold,\n",
        "        \"damaged_threshold\": damaged_threshold,\n",
        "        \"median_area_px\": median_area\n",
        "    }\n",
        "    return results, meta\n",
        "\n",
        "def annotate_polygons(img, results):\n",
        "    annotated = img.copy()\n",
        "    colors = {\n",
        "        \"normal\": (0, 255, 0),\n",
        "        \"broken\": (0, 0, 255),\n",
        "        \"chalky\": (0, 165, 255),\n",
        "        \"damaged\": (128, 0, 128),\n",
        "        \"foreign\": (255, 0, 0)\n",
        "    }\n",
        "    for r in results:\n",
        "        contour = r[\"contour\"]\n",
        "        label = r.get(\"label\", \"normal\")\n",
        "        color = colors.get(label, (255,255,255))\n",
        "        cv2.drawContours(annotated, [contour], -1, color, 2, cv2.LINE_AA)\n",
        "        cx, cy = int(r[\"cx\"]), int(r[\"cy\"])\n",
        "        cv2.circle(annotated, (cx, cy), 2, color, -1)\n",
        "    return annotated\n",
        "\n",
        "def pixels_to_mm(avg_pixel_length_px, target_avg_mm=6.0):\n",
        "    if avg_pixel_length_px <= 0:\n",
        "        return 0.0\n",
        "    return float(target_avg_mm / avg_pixel_length_px)\n",
        "\n",
        "# Streamlit inputs\n",
        "uploaded = st.file_uploader(\"Upload a rice image (jpg/png)\", type=[\"jpg\",\"jpeg\",\"png\"])\n",
        "camera_img = st.camera_input(\"Or capture from your camera\")\n",
        "\n",
        "image_bytes = None\n",
        "if uploaded is not None:\n",
        "    image_bytes = uploaded.read()\n",
        "elif camera_img is not None:\n",
        "    image_bytes = camera_img.getvalue()\n",
        "\n",
        "if image_bytes is not None:\n",
        "    pil = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    img = np.array(pil)[:, :, ::-1].copy()\n",
        "    gray, binary = preprocess(img)\n",
        "    contours = extract_grain_contours(binary, min_area)\n",
        "    feats = [grain_features(gray, c) for c in contours]\n",
        "    results, meta = classify_grains(feats, broken_ratio, chalky_percentile, damaged_percentile,\n",
        "                                    foreign_solidity_thresh, foreign_area_multiplier, foreign_aspect_ratio)\n",
        "\n",
        "    total = len(results)\n",
        "    count_broken = sum(1 for r in results if r[\"label\"] == \"broken\")\n",
        "    count_chalky = sum(1 for r in results if r[\"label\"] == \"chalky\")\n",
        "    count_damaged = sum(1 for r in results if r[\"label\"] == \"damaged\")\n",
        "    count_foreign = sum(1 for r in results if r[\"label\"] == \"foreign\")\n",
        "    count_normal = sum(1 for r in results if r[\"label\"] == \"normal\")\n",
        "\n",
        "    avg_len_px = float(np.mean([r[\"length_px\"] for r in results])) if total else 0.0\n",
        "    avg_wid_px = float(np.mean([r[\"width_px\"] for r in results])) if total else 0.0\n",
        "    mm_per_px = pixels_to_mm(avg_len_px, target_avg_mm=6.0) if avg_len_px > 0 else 0.0\n",
        "    avg_len_mm = avg_len_px * mm_per_px\n",
        "    avg_wid_mm = avg_wid_px * mm_per_px\n",
        "\n",
        "    pct_broken = (count_broken / total * 100.0) if total else 0.0\n",
        "    pct_chalky = (count_chalky / total * 100.0) if total else 0.0\n",
        "    pct_damaged = (count_damaged / total * 100.0) if total else 0.0\n",
        "    pct_foreign = (count_foreign / total * 100.0) if total else 0.0\n",
        "    pct_normal = (count_normal / total * 100.0) if total else 0.0\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.subheader(\"Counts\")\n",
        "        st.metric(\"Total detected\", total)\n",
        "        st.metric(\"Normal\", f\"{count_normal} ({pct_normal:.1f}%)\")\n",
        "        st.metric(\"Broken\", f\"{count_broken} ({pct_broken:.1f}%)\")\n",
        "        st.metric(\"Chalky\", f\"{count_chalky} ({pct_chalky:.1f}%)\")\n",
        "        st.metric(\"Damaged/Discoloured\", f\"{count_damaged} ({pct_damaged:.1f}%)\")\n",
        "        st.metric(\"Foreign matter\", f\"{count_foreign} ({pct_foreign:.1f}%)\")\n",
        "\n",
        "        st.subheader(\"Averages (mm)\")\n",
        "        st.write(f\"Average length: **{avg_len_mm:.2f} mm**\")\n",
        "        st.write(f\"Average width: **{avg_wid_mm:.2f} mm**\")\n",
        "        st.caption(\"Calibration: detected avg length mapped to 6.0 mm for conversion. Replace with known mm-per-pixel for accurate absolute sizing.\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Annotated (polygons)\")\n",
        "        annotated = annotate_polygons(img, results)\n",
        "        display_img = annotated[:, :, ::-1]\n",
        "        st.image(display_img, caption=\"Green=Normal, Red=Broken, Orange=Chalky, Purple=Damaged, Blue=Foreign\", use_column_width=True)\n",
        "\n",
        "        buffer = BytesIO()\n",
        "        pil_out = Image.fromarray(display_img)\n",
        "        pil_out.save(buffer, format=\"PNG\")\n",
        "        buffer.seek(0)\n",
        "        st.download_button(\"Download annotated image\", data=buffer, file_name=\"annotated.png\", mime=\"image/png\")\n",
        "\n",
        "\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload an image or use the camera to start analysis.\")\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"app.py written\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcLl0Y_eCR7z",
        "outputId": "ab4654eb-1067-46ab-a2a0-95be4030a307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py written\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "# pick a file to upload to /content\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "J6aX07EHCTzE",
        "outputId": "1bea9dc4-babe-4aee-c4af-41ac5a8250be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-135035a7-bcea-4ec7-9c6f-295eb40916c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-135035a7-bcea-4ec7-9c6f-295eb40916c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Gemini_Generated_Image_htq3jxhtq3jxhtq3.png to Gemini_Generated_Image_htq3jxhtq3jxhtq3.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, time, os, requests\n",
        "from pyngrok import ngrok\n",
        "\n",
        "token = os.environ.get(\"NGROK_AUTHTOKEN\", \"\")\n",
        "if token:\n",
        "    ngrok.set_auth_token(token)\n",
        "\n",
        "# start streamlit\n",
        "proc = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# wait for local server to respond\n",
        "start = time.time()\n",
        "\n",
        "timeout = 40\n",
        "while True:\n",
        "    try:\n",
        "        r = requests.get(\"http://localhost:8501\")\n",
        "        if r.status_code < 500:\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "    if time.time() - start > timeout:\n",
        "        print(\"Warning: Streamlit did not respond within timeout; check logs.\")\n",
        "        break\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# create tunnel and print public URL\n",
        "public_url = ngrok.connect(8501, \"http\").public_url\n",
        "print(\"Public URL:\", public_url)\n",
        "print(\"If the URL fails, restart this cell. Remove ngrok token cell before sharing notebook.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nojKiLuMCWpo",
        "outputId": "a617048c-e16d-42de-cb92-c1e3484a501c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://wormlike-magdalen-deductively.ngrok-free.dev\n",
            "If the URL fails, restart this cell. Remove ngrok token cell before sharing notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show logs from the running Streamlit process\n",
        "import time, sys\n",
        "for _ in range(200):\n",
        "    line = proc.stderr.readline()\n",
        "    if not line:\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "    try:\n",
        "        print(line.decode('utf-8', errors='ignore').rstrip())\n",
        "    except:\n",
        "        print(line)\n"
      ],
      "metadata": {
        "id": "v3PfXXkmCbtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3y6VgziCeJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
